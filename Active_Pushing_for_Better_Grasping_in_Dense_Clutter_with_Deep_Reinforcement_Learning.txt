what your paper is about
	无结构密集杂乱环境中的机器人抓取（robot grasping in unstructured dense clutter）
what problem it solves
	不同动作协同抓取物体存在一些问题（在没有物体的区域进行无效推动、抓取效率较低）
why the problem is interesting
	抓取动作和非抓取动作结合（推动、拉、倾倒？这几个动作的区别、滚动、刷动？）
	提出一些新机制，离散度和协调机制（可以看看如何设计）
what is really new (and what isn't)
	is
	引入基于新标准的主动推动机制（离散度），可以描述环境中的物体是如何扩散的，用于计算推动网络的奖励（用于减少无效推动）
		Using Manipulation Primitives for Brick Sorting in Clutter
	设计协调机制，根据动作值和物体的离散度应用不同动作之间的协同作用（？）
	isn't
	使用全卷积动作价值函数将视觉观察映射到Q-Learning框架中的两个动作价值表（推动/抓取）上（？）
	设计了推抓结合的网络（进行了创新）
why it's so neat（巧妙之处）
	通过离散度对推动的成功与否和奖励进行定义，解决了2018那篇文章只通过环境改变判断推动是否成功的（已经被解决了）
	提高了抓取效率、增强泛化能力，推动到合适的位置时才会抓取（如何实现）
	动作空间离散化为与场景图像像素对应的像素级运动原语、机器人操作任务描述为像素级分割问题（？）这种方式不是使用深度强化学习端到端策略训练吗？

方法介绍：
	1）FCN提取出状态图的RGB特征和DDD特征
	2）分别输入DenseNet，输出在通道级别上拼接，然后2 additional convolutional layers with bilinear interpolation（上采样+卷积？）
	3）协作机制没有具体介绍__
	4）重点：离散度的定义、计算场景中物体的分离程度，用于判断推动的起作用的程度（有时候改变环境推动可能会有副作用）
		过程：I、计算物体中心坐标之间的距离，每个物体均可通过语义分割方法（FCN、SegNet等）/目标检测方法（Yolo等）从场景中分割出来
		          II、两物体距离大于夹爪距离，说明在抓取时两物体不会相互影响（使用公式对离散度进行定义）
		          III、离散度为1表示物体之间完全独立，不需要再推动
		奖励：前后两个状态离散度大于一个阈值时推动获得奖励
			疑惑：1、阈值很小，仅0.005（理由？）
			          2、本以为是奖励和离散度成一个函数关系，但文章中是离散度只要增大，就可以得到推动奖励
			          3、离散度不变或者减小表示推动为副作用，如何理解为减小噪声干扰，阈值设为0.005（本来应该是只要增大就可以，但是为了防止扰动造成的增大，设置了一个0.005）
			          4、dipn 假设推动的合成图片的离散度 还是 实际推动的离散度（离散度仅是计算奖励的指标，不是策略的指标）
	5）协作系统：考虑了离散度（DD）、最大抓取Q值、最大推动Q值，设计了公式
		      判据大于0.5时，选择推动作（这个设计的公式的依据？真的解决了遮挡问题和推动把物块推出工作空间的问题吗？）
	6）网络训练：I、如何对推和抓分别进行训练（）
		      II、推动策略训练使用到了课程学习（从易到难）
		      III、抓取训练包括可抓取的物体和太大无法抓取的物体（防止夹爪在密集区域进行抓取）
		      IV、使用了优先级经验回放（prioritized experience replay）[31]，其中采用了随机基于排名的优先级策略
实验：
	1）推动实验结果
		和VPG的推动模块对比 对比一定推动之后离散度和有效推动的百分比（具体如何实现VPG仅进行推动、VPG网络也是仅对推动进行训练还是训练了推抓）
	2）抓取实验结果
		